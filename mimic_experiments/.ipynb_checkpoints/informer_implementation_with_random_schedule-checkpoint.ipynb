{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d86537",
   "metadata": {},
   "source": [
    "*ToDo*\n",
    "\n",
    "02) pred_window und obs_window ausprobieren.\n",
    "03) output nochmal genau anschauen.\n",
    "04) was ist maskiert anschauen - und wie genau?\n",
    "05) VRAM wenig ausgelastet. Batch size mal mit 320 ausprobieren, aber auch durchziehen.\n",
    "06) Task pred: scheduler einfügen.\n",
    "07) Analyse each var (sparsity)\n",
    "08) loss per var/quality of varis loss (is this already ablation to forecast only one var)\n",
    "09) Include sepsis definition\n",
    "10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driven-termination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T13:33:31.302705Z",
     "iopub.status.busy": "2023-12-19T13:33:31.301797Z",
     "iopub.status.idle": "2023-12-19T13:33:34.799260Z",
     "shell.execute_reply": "2023-12-19T13:33:34.798242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c94544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T13:33:34.803821Z",
     "iopub.status.busy": "2023-12-19T13:33:34.803346Z",
     "iopub.status.idle": "2023-12-19T13:33:34.810914Z",
     "shell.execute_reply": "2023-12-19T13:33:34.810023Z"
    }
   },
   "outputs": [],
   "source": [
    "# data settings\n",
    "test_cond = 0\n",
    "\n",
    "if test_cond == 1:\n",
    "    data_path = '/home/mitarb/fracarolli/files/231113_STraTS_new/mimic_iii_preprocessed_new_z_err20092.pkl'\n",
    "    sample_divisor = 100\n",
    "    number_of_epochs = 20\n",
    "else:\n",
    "    data_path = '/home/mitarb/fracarolli/files/231113_STraTS_new/mimic_iii_preprocessed_new_z_err20092.pkl'\n",
    "    sample_divisor = 1\n",
    "    number_of_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-record",
   "metadata": {},
   "source": [
    "## Load forecast dataset into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fdc7de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T13:33:34.814004Z",
     "iopub.status.busy": "2023-12-19T13:33:34.813781Z",
     "iopub.status.idle": "2023-12-19T13:33:34.821047Z",
     "shell.execute_reply": "2023-12-19T13:33:34.819955Z"
    }
   },
   "outputs": [],
   "source": [
    "def inv_list(l, start=0):  # Create vind\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    mask   = [0 for i in range(V)]\n",
    "    values = [0 for i in range(V)]\n",
    "    #print('hi', mask , V)\n",
    "    #mask, values = np.zeros(V), np.zeros(V)\n",
    "    #print('hi', mask)\n",
    "    for vv in x:  # tuple of ['vind','value']\n",
    "        v = int(vv[0])-1  # shift index of vind\n",
    "        mask[v] = 1\n",
    "        values[v] = vv[1]  # get value\n",
    "    return values+mask  # concat\n",
    "\n",
    "\n",
    "def pad(x):\n",
    "    if len(x) > 880:\n",
    "        print(len(x))\n",
    "    return x+[0]*(fore_max_len-len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executive-annual",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T13:33:34.824585Z",
     "iopub.status.busy": "2023-12-19T13:33:34.824362Z",
     "iopub.status.idle": "2023-12-19T14:34:31.507957Z",
     "shell.execute_reply": "2023-12-19T14:34:31.506747Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87010it [00:00, 408826.56it/s]\n",
      "100%|██████████| 25/25 [1:03:34<00:00, 152.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278698, 48, 262)\n",
      "lengths of rem_sub, fore_train_ip[1], fore_valid_ip[0]\n",
      "15869 (242592, 880) (77263, 2)\n"
     ]
    }
   ],
   "source": [
    "pred_window_old = 12  # hours\n",
    "obs_windows = range(0, 1, 1)\n",
    "\n",
    "# Read data.\n",
    "data, oc, train_ind, valid_ind, test_ind = pickle.load(open(data_path, 'rb'))\n",
    "# Remove test patients.\n",
    "data = data.merge(oc[['ts_ind', 'SUBJECT_ID']], on='ts_ind', how='left')\n",
    "test_sub = oc.loc[oc.ts_ind.isin(test_ind)].SUBJECT_ID.unique()\n",
    "data = data.loc[~data.SUBJECT_ID.isin(test_sub)]\n",
    "oc = oc.loc[~oc.SUBJECT_ID.isin(test_sub)]\n",
    "data.drop(columns=['SUBJECT_ID', 'TABLE'], inplace=True)\n",
    "# Fix age.\n",
    "data.loc[(data.variable == 'Age') & (data.value > 200), 'value'] = 91.4\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]  # static data are 'Age' and 'Gender'\n",
    "data = data.loc[~ii]  # ~ binary flip\n",
    "# print('data\\n',data)\n",
    "\n",
    "static_var_to_ind = inv_list(static_varis)  # {'Age': 0, 'Gender': 1}\n",
    "D = len(static_varis)  # 2 by definition\n",
    "N = data.ts_ind.max()+1  # /= 12: 52861\n",
    "demo = np.zeros((int(N), int(D)))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[int(row.ts_ind), static_var_to_ind[row.variable]] = row.value\n",
    "# print('Demo after tqdm command \\n',demo[:10])\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)  # quite sparse\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds == 0)*1 + (stds != 0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# print('Demo after normalisation \\n',demo[:10])\n",
    "# Get variable indices.\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)  # 129 for \\=12 with varis all variables except for static ones\n",
    "# print('varis', varis, V)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# print('data vind\\n', data['vind'], '\\n data\\n',data)\n",
    "# Find max_len.\n",
    "fore_max_len = 880  # hard coded max_len of vars\n",
    "# Get forecast inputs and outputs.\n",
    "fore_times_ip = []\n",
    "fore_values_ip = []\n",
    "fore_varis_ip = []\n",
    "fore_op = []\n",
    "fore_op_awesome = []\n",
    "fore_inds = []\n",
    "for w in tqdm(range(25, 124, 4)):  # range(20, 124, 4), pred_window=2\n",
    "    pred_data = data.loc[(data.hour>=w)&(data.hour<=w+24)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "    pred_data['vind_value'] = pred_data['vind_value'].apply(f)   \n",
    "\n",
    "    obs_data = data.loc[(data.hour < w) & (data.hour >= w-24)]\n",
    "    obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "    obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "    obs_data = obs_data.groupby('ts_ind').agg({'vind': list, 'hour': list, 'value': list}).reset_index()\n",
    "    #Michi: Hier hole ich mir die 24 Stunden vor, und 24 Stunden nach einem bestimmten Zeitpunkt raus\n",
    "    for pred_window  in range(-24, 24, 1):\n",
    "        pred_data = data.loc[(data.hour >= w+pred_window) & (data.hour <= w+1 +pred_window)]\n",
    "        pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value': 'first'}).reset_index()\n",
    "        pred_data['vind_value'+str(pred_window)] = pred_data[['vind', 'value']].values.tolist()\n",
    "        pred_data = pred_data.groupby('ts_ind').agg({'vind_value'+str(pred_window): list}).reset_index()\n",
    "        pred_data['vind_value'+str(pred_window)] = pred_data['vind_value'+str(pred_window)].apply(f)  # 721 entries with 2*129 vind_values\n",
    "        obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "\n",
    "    for col in ['vind', 'hour', 'value']:\n",
    "        obs_data[col] = obs_data[col].apply(pad)\n",
    "    fore_op_awesome.append(np.array(list([list(obs_data['vind_value'+str(pred_window)]) for pred_window in range(-24, 24, 1)])))\n",
    "    #fore_op.append(np.array(list(obs_data.vind_value)))\n",
    "    fore_inds.append(np.array([int(x) for x in list(obs_data.ts_ind)]))\n",
    "    fore_times_ip.append(np.array(list(obs_data.hour)))\n",
    "    fore_values_ip.append(np.array(list(obs_data.value)))\n",
    "    fore_varis_ip.append(np.array(list(obs_data.vind)))\n",
    "    \n",
    "del data\n",
    "fore_times_ip = np.concatenate(fore_times_ip, axis=0)\n",
    "fore_values_ip = np.concatenate(fore_values_ip, axis=0)\n",
    "fore_varis_ip = np.concatenate(fore_varis_ip, axis=0)\n",
    "\n",
    "fore_op_awesome = np.concatenate(fore_op_awesome, axis=1)\n",
    "fore_op = np.swapaxes(fore_op_awesome, 0, 1)\n",
    "print(fore_op.shape)\n",
    "\n",
    "#raise Exception\n",
    "fore_inds = np.concatenate(fore_inds, axis=0)\n",
    "fore_demo = demo[fore_inds]\n",
    "# Get train and valid ts_ind for forecast task.\n",
    "train_sub = oc.loc[oc.ts_ind.isin(train_ind)].SUBJECT_ID.unique()\n",
    "valid_sub = oc.loc[oc.ts_ind.isin(valid_ind)].SUBJECT_ID.unique()\n",
    "rem_sub = oc.loc[~oc.SUBJECT_ID.isin(np.concatenate((train_ind, valid_ind)))].SUBJECT_ID.unique()\n",
    "bp = int(0.8*len(rem_sub))\n",
    "train_sub = np.concatenate((train_sub, rem_sub[:bp]))\n",
    "valid_sub = np.concatenate((valid_sub, rem_sub[bp:]))\n",
    "train_ind = oc.loc[oc.SUBJECT_ID.isin(train_sub)].ts_ind.unique()  # Add remaining ts_ind s of train subjects.\n",
    "valid_ind = oc.loc[oc.SUBJECT_ID.isin(valid_sub)].ts_ind.unique()  # Add remaining ts_ind s of train subjects.\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ind = np.argwhere(np.in1d(fore_inds, train_ind)).flatten()\n",
    "valid_ind = np.argwhere(np.in1d(fore_inds, valid_ind)).flatten()\n",
    "fore_train_ip = [ip[train_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "fore_valid_ip = [ip[valid_ind] for ip in [fore_demo, fore_times_ip, fore_values_ip, fore_varis_ip]]\n",
    "del fore_times_ip, fore_values_ip, fore_varis_ip, demo, fore_demo\n",
    "fore_train_op = fore_op[train_ind]\n",
    "fore_valid_op = fore_op[valid_ind]\n",
    "del fore_op\n",
    "\n",
    "print('lengths of rem_sub, fore_train_ip[1], fore_valid_ip[0]')\n",
    "print(len(rem_sub), fore_train_ip[1].shape, fore_valid_ip[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8fd59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:34:31.512431Z",
     "iopub.status.busy": "2023-12-19T14:34:31.512104Z",
     "iopub.status.idle": "2023-12-19T14:34:31.603050Z",
     "shell.execute_reply": "2023-12-19T14:34:31.602048Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sofa(matrix): #24x131 matrix\n",
    "    # GCS: min_eye, min_motor, min_verbal = 5, 5, 5\n",
    "    print(matrix.size())\n",
    "    #raise Exception\n",
    "    key =\"GCS_eye\"\n",
    "    a=matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]\n",
    "    print(a)\n",
    "    min_eye = min(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=5)\n",
    "    #print(\"calculatedvalue\", min_eye)\n",
    "    #print(\"table_value\", matrix[:, var_to_ind[key]])\n",
    "    #print(\"std\", mean_std_dict[key][1])\n",
    "    #print(\"mean\", mean_std_dict[key][0])\n",
    "    key = \"GCS_motor\"\n",
    "    min_motor = min(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=5)\n",
    "    key = \"GCS_verbal\"\n",
    "    min_verbal = min(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=5)\n",
    "    \n",
    "\n",
    "    GCS = min_eye + min_motor + min_verbal\n",
    "    if GCS > 14: GCS_sofa = 0\n",
    "    elif GCS > 12: GCS_sofa = 1\n",
    "    elif GCS > 9:  GCS_sofa = 2\n",
    "    elif GCS > 5:  GCS_sofa = 3\n",
    "    else: GCS_sofa = 4\n",
    "    print('GCS_sofa is', GCS_sofa, ';     GCS is', GCS,'; GCS eye', min_eye, '; GCS motor', min_motor, '; GCS verbal', min_verbal)\n",
    "\n",
    "    # bilirubin Liver SOFA\n",
    "\n",
    "    key = \"Bilirubin (Total)\"\n",
    "    bilir = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "    print(\"calculatedvalue\", bilir)\n",
    "    print(\"table_value\", matrix[:, var_to_ind[key]])\n",
    "    print(\"std\", mean_std_dict[key][1])\n",
    "    print(\"mean\", mean_std_dict[key][0])\n",
    "    if bilir > 12: bilir_sofa = 4\n",
    "    elif bilir > 6: bilir_sofa = 3\n",
    "    elif bilir > 2: bilir_sofa = 2\n",
    "    elif bilir > 1.2: bilir_sofa = 1\n",
    "    else: bilir_sofa = 0\n",
    "    print('bilir_Sofa is', bilir_sofa, ';   bilirubin is', bilir)\n",
    "    \n",
    "    # Coagulation (Platelets)\n",
    "    key = \"Platelet Count\"\n",
    "    plate = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=160)\n",
    "    if plate > 150: plate_sofa = 0\n",
    "    elif plate > 100: plate_sofa = 1\n",
    "    elif plate > 50: plate_sofa = 2\n",
    "    elif plate > 20: plate_sofa = 4\n",
    "    else: plate_sofa = 4\n",
    "    print('plate_sofa is', plate_sofa, ';   platelet count is', plate)\n",
    "    \n",
    "    # print('Urinmenge 24h', sum(data_var[data_var['variable']=='Urine']['value2']))\n",
    "\n",
    "    key = \"Urine\"\n",
    "    urine = sum(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0])\n",
    "    key = \"Creatinine Blood\"\n",
    "    creat = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "    \n",
    "    if (urine < 200) or (creat > 5): renal_sofa = 4\n",
    "    elif  (urine < 500) or (creat > 3.5): renal_sofa = 3\n",
    "    elif creat > 2.0: renal_sofa = 2\n",
    "    elif creat > 1.2: renal_sofa = 1\n",
    "    else: renal_sofa = 0\n",
    "    print('renal_sofa:',renal_sofa,';       urine 24:',urine,'; creat:', creat)\n",
    "    \n",
    "    CS_data = get_CS(matrix)\n",
    "    cs_sofa = CS_SOFA(CS_data)\n",
    "    \n",
    "    #cs_sofa = 0\n",
    "    key=\"FiO2\"\n",
    "    fio2 = (matrix[:, var_to_ind[key]]*mean_std_dict[key][1]+mean_std_dict[key][0])\n",
    "    key=\"PO2\"\n",
    "    po2 = (matrix[:, var_to_ind[key]]*mean_std_dict[key][1]+mean_std_dict[key][0])\n",
    "    PaO2FiO2 = 100*po2/fio2\n",
    "    print(\"size\", PaO2FiO2.size())\n",
    "    PaO2FiO2 = PaO2FiO2[torch.nonzero(PaO2FiO2, as_tuple=True)]\n",
    "    pao2fio2 = min(PaO2FiO2)\n",
    "    if pao2fio2<100: resp=4\n",
    "    elif pao2fio2<200: resp=3\n",
    "    elif pao2fio2<300:resp=2\n",
    "    elif pao2fio2<400:resp=1\n",
    "    else: resp=0\n",
    "    return GCS_sofa, cs_sofa, resp, plate_sofa, bilir_sofa, renal_sofa\n",
    "\n",
    "def get_CS(matrix):\n",
    "    #data_var = data_pat[data_pat['variable'].isin(['Dobutamine','Dopamine','Epinephrine','Norepinephrine','Weight'])]\n",
    "    #data_var['value2'] = data_var['value']*data_var['std']+data_var['mean']\n",
    "    \n",
    "    #weight = min(data_var[data_var['variable']=='Weight']['value2'], default=80)  # set default weight to 80kg.\n",
    "    key = \"Weight\"\n",
    "    weight = min(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)], default=80)#*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "    key = \"Dopamine\"\n",
    "    try:\n",
    "        data_dop = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "        data_dop = data_dop /60/weight*1000\n",
    "    except:\n",
    "        data_dop = 0\n",
    "\n",
    "    key = \"Dobutamine\"\n",
    "    \n",
    "    try:\n",
    "        data_dobu = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "        data_dobu = data_dop /60/weight*1000\n",
    "    except:\n",
    "        data_dobu = 0\n",
    "    key = \"Epinephrine\"\n",
    "    \n",
    "    try:\n",
    "        data_epi = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "        data_epi = data_dop /60/weight*1000\n",
    "    except:\n",
    "        data_epi = 0\n",
    "    key = \"Norepinephrine\"\n",
    "    \n",
    "    try:\n",
    "        data_nore = max(matrix[:, var_to_ind[key]][torch.nonzero(matrix[:, var_to_ind[key]], as_tuple=True)]*mean_std_dict[key][1]+mean_std_dict[key][0], default=1)\n",
    "        data_nore = data_dop /60/weight*1000\n",
    "    except:\n",
    "        data_nore = 0\n",
    "        \n",
    "\n",
    "\n",
    "    key = \"SBP\"\n",
    "    SBP = (matrix[:, var_to_ind[key]]*mean_std_dict[key][1]+mean_std_dict[key][0])\n",
    "\n",
    "    key = \"DBP\"\n",
    "    DBP = (matrix[:, var_to_ind[key]]*mean_std_dict[key][1]+mean_std_dict[key][0])\n",
    "\n",
    "    MAP = 2/3 * DBP + 1/3 * SBP\n",
    "    MAP = min(MAP[torch.nonzero(MAP, as_tuple=True)], default=100)\n",
    "                 \n",
    "        \n",
    "    return MAP, data_dop, data_dobu, data_epi, data_nore \n",
    "    \n",
    "def CS_SOFA(data):\n",
    "    map = data[0]\n",
    "    dop, dobu, epi, nore = data[1:5]\n",
    "    # print('CS data: mdden', data)\n",
    "    if (dop > 15) or (epi > 0.1) or (nore > 0.01): CS = 4\n",
    "    elif (dop > 5) or (epi > 0) or (nore > 0): CS = 3\n",
    "    elif (dop > 0) or (dobu > 0): CS = 2\n",
    "    elif map < 70: CS = 1\n",
    "    else: CS = 0\n",
    "    # print('CS Sofa is:', CS)\n",
    "    return CS \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b18c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:34:31.606543Z",
     "iopub.status.busy": "2023-12-19T14:34:31.606243Z",
     "iopub.status.idle": "2023-12-19T14:42:20.705077Z",
     "shell.execute_reply": "2023-12-19T14:42:20.704068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.keys of                    mean          std\n",
      "variable                            \n",
      "ALP          154.628076   175.683383\n",
      "ALT          245.082850   781.463478\n",
      "AST          316.982503  1145.343129\n",
      "Age           74.796296    54.740381\n",
      "Albumin        2.797052     0.653217\n",
      "...                 ...          ...\n",
      "Vasopressin    2.317580     3.052470\n",
      "WBC           12.294918     9.052268\n",
      "Weight        84.374929    25.456139\n",
      "pH Blood       7.384243     0.082493\n",
      "pH Urine       5.762298     0.951732\n",
      "\n",
      "[133 rows x 2 columns]>\n",
      "ALP\n",
      "mean    154.628076\n",
      "std     175.683383\n",
      "Name: ALP, dtype: float64\n",
      "ALT\n",
      "mean    245.082850\n",
      "std     781.463478\n",
      "Name: ALT, dtype: float64\n",
      "AST\n",
      "mean     316.982503\n",
      "std     1145.343129\n",
      "Name: AST, dtype: float64\n",
      "Age\n",
      "mean    74.796296\n",
      "std     54.740381\n",
      "Name: Age, dtype: float64\n",
      "Albumin\n",
      "mean    2.797052\n",
      "std     0.653217\n",
      "Name: Albumin, dtype: float64\n",
      "Albumin 25%\n",
      "mean    64.733569\n",
      "std     58.360216\n",
      "Name: Albumin 25%, dtype: float64\n",
      "Albumin 5%\n",
      "mean    311.883998\n",
      "std     159.777391\n",
      "Name: Albumin 5%, dtype: float64\n",
      "Amiodarone\n",
      "mean    38.529795\n",
      "std     26.307409\n",
      "Name: Amiodarone, dtype: float64\n",
      "Anion Gap\n",
      "mean    13.700320\n",
      "std      4.025733\n",
      "Name: Anion Gap, dtype: float64\n",
      "Antibiotics\n",
      "mean    1.0\n",
      "std     1.0\n",
      "Name: Antibiotics, dtype: float64\n",
      "BUN\n",
      "mean    32.633869\n",
      "std     25.762741\n",
      "Name: BUN, dtype: float64\n",
      "Base Excess\n",
      "mean    0.040568\n",
      "std     5.100587\n",
      "Name: Base Excess, dtype: float64\n",
      "Basophils\n",
      "mean    0.235105\n",
      "std     0.548725\n",
      "Name: Basophils, dtype: float64\n",
      "Bicarbonate\n",
      "mean    24.799389\n",
      "std      5.256608\n",
      "Name: Bicarbonate, dtype: float64\n",
      "Bilirubin (Direct)\n",
      "mean    4.430014\n",
      "std     5.869894\n",
      "Name: Bilirubin (Direct), dtype: float64\n",
      "Bilirubin (Indirect)\n",
      "mean    2.066711\n",
      "std     2.608665\n",
      "Name: Bilirubin (Indirect), dtype: float64\n",
      "Bilirubin (Total)\n",
      "mean    4.068490\n",
      "std     7.385233\n",
      "Name: Bilirubin (Total), dtype: float64\n",
      "CRR\n",
      "mean    0.046815\n",
      "std     0.204202\n",
      "Name: CRR, dtype: float64\n",
      "Calcium Free\n",
      "mean    1.131974\n",
      "std     0.113125\n",
      "Name: Calcium Free, dtype: float64\n",
      "Calcium Gluconate\n",
      "mean    1.193192\n",
      "std     2.055239\n",
      "Name: Calcium Gluconate, dtype: float64\n",
      "Calcium Total\n",
      "mean    8.336291\n",
      "std     0.842840\n",
      "Name: Calcium Total, dtype: float64\n",
      "Cefazolin\n",
      "mean    1.004076\n",
      "std     0.064029\n",
      "Name: Cefazolin, dtype: float64\n",
      "Chest Tube\n",
      "mean    39.943713\n",
      "std     77.128775\n",
      "Name: Chest Tube, dtype: float64\n",
      "Chloride\n",
      "mean    104.925838\n",
      "std       6.557635\n",
      "Name: Chloride, dtype: float64\n",
      "Colloid\n",
      "mean     693.240026\n",
      "std     1386.959077\n",
      "Name: Colloid, dtype: float64\n",
      "Creatinine Blood\n",
      "mean    1.544304\n",
      "std     1.527146\n",
      "Name: Creatinine Blood, dtype: float64\n",
      "Creatinine Urine\n",
      "mean    82.663541\n",
      "std     61.050576\n",
      "Name: Creatinine Urine, dtype: float64\n",
      "D5W\n",
      "mean    41.319438\n",
      "std     79.481519\n",
      "Name: D5W, dtype: float64\n",
      "DBP\n",
      "mean    60.220559\n",
      "std     14.646605\n",
      "Name: DBP, dtype: float64\n",
      "Dextrose Other\n",
      "mean    72.693703\n",
      "std     67.177799\n",
      "Name: Dextrose Other, dtype: float64\n",
      "Dobutamine\n",
      "mean    23.437136\n",
      "std     29.676816\n",
      "Name: Dobutamine, dtype: float64\n",
      "Dopamine\n",
      "mean    26.417415\n",
      "std     30.536951\n",
      "Name: Dopamine, dtype: float64\n",
      "EBL\n",
      "mean     503.289466\n",
      "std     1101.237492\n",
      "Name: EBL, dtype: float64\n",
      "Emesis\n",
      "mean    126.001879\n",
      "std     161.990896\n",
      "Name: Emesis, dtype: float64\n",
      "Eoisinophils\n",
      "mean    1.479122\n",
      "std     2.782645\n",
      "Name: Eoisinophils, dtype: float64\n",
      "Epinephrine\n",
      "mean    0.170302\n",
      "std     0.556719\n",
      "Name: Epinephrine, dtype: float64\n",
      "Famotidine\n",
      "mean    1.0\n",
      "std     1.0\n",
      "Name: Famotidine, dtype: float64\n",
      "Fentanyl\n",
      "mean    0.103347\n",
      "std     0.141797\n",
      "Name: Fentanyl, dtype: float64\n",
      "FiO2\n",
      "mean    0.495462\n",
      "std     0.157418\n",
      "Name: FiO2, dtype: float64\n",
      "Fiber\n",
      "mean    56.385602\n",
      "std     38.513257\n",
      "Name: Fiber, dtype: float64\n",
      "Free Water\n",
      "mean    164.512766\n",
      "std     105.488156\n",
      "Name: Free Water, dtype: float64\n",
      "Fresh Frozen Plasma\n",
      "mean    240.281549\n",
      "std     288.320782\n",
      "Name: Fresh Frozen Plasma, dtype: float64\n",
      "Furosemide\n",
      "mean    10.046008\n",
      "std     13.290645\n",
      "Name: Furosemide, dtype: float64\n",
      "GCS_eye\n",
      "mean    3.282005\n",
      "std     1.061469\n",
      "Name: GCS_eye, dtype: float64\n",
      "GCS_motor\n",
      "mean    5.271424\n",
      "std     1.410323\n",
      "Name: GCS_motor, dtype: float64\n",
      "GCS_verbal\n",
      "mean    2.964443\n",
      "std     1.905070\n",
      "Name: GCS_verbal, dtype: float64\n",
      "GT Flush\n",
      "mean    51.024503\n",
      "std     59.902241\n",
      "Name: GT Flush, dtype: float64\n",
      "Gastric\n",
      "mean    161.617138\n",
      "std     187.566646\n",
      "Name: Gastric, dtype: float64\n",
      "Gastric Meds\n",
      "mean    65.348545\n",
      "std     93.295265\n",
      "Name: Gastric Meds, dtype: float64\n",
      "Gender\n",
      "mean    0.436765\n",
      "std     0.495990\n",
      "Name: Gender, dtype: float64\n",
      "Glucose (Blood)\n",
      "mean    141.672325\n",
      "std      55.695745\n",
      "Name: Glucose (Blood), dtype: float64\n",
      "Glucose (Serum)\n",
      "mean    136.285481\n",
      "std      60.258489\n",
      "Name: Glucose (Serum), dtype: float64\n",
      "Glucose (Whole Blood)\n",
      "mean    132.329913\n",
      "std      44.977708\n",
      "Name: Glucose (Whole Blood), dtype: float64\n",
      "HR\n",
      "mean    87.010048\n",
      "std     18.333656\n",
      "Name: HR, dtype: float64\n",
      "Half Normal Saline\n",
      "mean    75.761751\n",
      "std     89.859797\n",
      "Name: Half Normal Saline, dtype: float64\n",
      "Hct\n",
      "mean    29.905473\n",
      "std      4.814677\n",
      "Name: Hct, dtype: float64\n",
      "Heparin\n",
      "mean    1114.044958\n",
      "std      792.458594\n",
      "Name: Heparin, dtype: float64\n",
      "Hgb\n",
      "mean    10.127966\n",
      "std      1.711197\n",
      "Name: Hgb, dtype: float64\n",
      "Hydralazine\n",
      "mean    11.771233\n",
      "std      4.973803\n",
      "Name: Hydralazine, dtype: float64\n",
      "Hydromorphone\n",
      "mean    2.917112\n",
      "std     7.776264\n",
      "Name: Hydromorphone, dtype: float64\n",
      "INR\n",
      "mean    1.585326\n",
      "std     1.129499\n",
      "Name: INR, dtype: float64\n",
      "Insulin Humalog\n",
      "mean    5.131420\n",
      "std     5.680365\n",
      "Name: Insulin Humalog, dtype: float64\n",
      "Insulin NPH\n",
      "mean    17.326918\n",
      "std     14.400409\n",
      "Name: Insulin NPH, dtype: float64\n",
      "Insulin Regular\n",
      "mean    3.943551\n",
      "std     7.373561\n",
      "Name: Insulin Regular, dtype: float64\n",
      "Insulin largine\n",
      "mean    23.253535\n",
      "std     16.090941\n",
      "Name: Insulin largine, dtype: float64\n",
      "Intubated\n",
      "mean    0.819140\n",
      "std     0.384901\n",
      "Name: Intubated, dtype: float64\n",
      "Jackson-Pratt\n",
      "mean     83.749601\n",
      "std     120.171735\n",
      "Name: Jackson-Pratt, dtype: float64\n",
      "KCl\n",
      "mean    6.381031\n",
      "std     8.841727\n",
      "Name: KCl, dtype: float64\n",
      "KCl (Bolus)\n",
      "mean    52.503449\n",
      "std     17.747101\n",
      "Name: KCl (Bolus), dtype: float64\n",
      "LDH\n",
      "mean     616.844212\n",
      "std     1380.009266\n",
      "Name: LDH, dtype: float64\n",
      "Lactate\n",
      "mean    2.661545\n",
      "std     2.725842\n",
      "Name: Lactate, dtype: float64\n",
      "Lactated Ringers\n",
      "mean    139.507397\n",
      "std     227.059893\n",
      "Name: Lactated Ringers, dtype: float64\n",
      "Levofloxacin\n",
      "mean    0.995481\n",
      "std     0.042432\n",
      "Name: Levofloxacin, dtype: float64\n",
      "Lorazepam\n",
      "mean    3.604079\n",
      "std     6.978263\n",
      "Name: Lorazepam, dtype: float64\n",
      "Lymphocytes\n",
      "mean    11.765740\n",
      "std     11.730555\n",
      "Name: Lymphocytes, dtype: float64\n",
      "Lymphocytes (Absolute)\n",
      "mean     989.39604\n",
      "std     1160.22688\n",
      "Name: Lymphocytes (Absolute), dtype: float64\n",
      "MBP\n",
      "mean    79.181704\n",
      "std     17.064872\n",
      "Name: MBP, dtype: float64\n",
      "MCH\n",
      "mean    30.245122\n",
      "std      2.261147\n",
      "Name: MCH, dtype: float64\n",
      "MCHC\n",
      "mean    33.699835\n",
      "std      1.591453\n",
      "Name: MCHC, dtype: float64\n",
      "MCV\n",
      "mean    89.850466\n",
      "std      6.202221\n",
      "Name: MCV, dtype: float64\n",
      "Magnesium\n",
      "mean    2.070392\n",
      "std     0.387002\n",
      "Name: Magnesium, dtype: float64\n",
      "Magnesium Sulfate (Bolus)\n",
      "mean    49.425955\n",
      "std      5.362459\n",
      "Name: Magnesium Sulfate (Bolus), dtype: float64\n",
      "Magnesium Sulphate\n",
      "mean    1.921051\n",
      "std     1.356352\n",
      "Name: Magnesium Sulphate, dtype: float64\n",
      "Mechanically ventilated\n",
      "mean    1.0\n",
      "std     1.0\n",
      "Name: Mechanically ventilated, dtype: float64\n",
      "Metoprolol\n",
      "mean    5.993671\n",
      "std     4.019041\n",
      "Name: Metoprolol, dtype: float64\n",
      "Midazolam\n",
      "mean    3.489651\n",
      "std     5.296792\n",
      "Name: Midazolam, dtype: float64\n",
      "Milrinone\n",
      "mean    1.612467\n",
      "std     1.298641\n",
      "Name: Milrinone, dtype: float64\n",
      "Monocytes\n",
      "mean    4.871427\n",
      "std     4.666159\n",
      "Name: Monocytes, dtype: float64\n",
      "Morphine Sulfate\n",
      "mean     5.612473\n",
      "std     27.682522\n",
      "Name: Morphine Sulfate, dtype: float64\n",
      "Neosynephrine\n",
      "mean    4.911317\n",
      "std     8.303943\n",
      "Name: Neosynephrine, dtype: float64\n",
      "Neutrophils\n",
      "mean    77.820383\n",
      "std     16.495818\n",
      "Name: Neutrophils, dtype: float64\n",
      "Nitroglycerine\n",
      "mean    5.086014\n",
      "std     7.363205\n",
      "Name: Nitroglycerine, dtype: float64\n",
      "Nitroprusside\n",
      "mean    5.562783\n",
      "std     8.607456\n",
      "Name: Nitroprusside, dtype: float64\n",
      "Norepinephrine\n",
      "mean    0.545942\n",
      "std     0.934379\n",
      "Name: Norepinephrine, dtype: float64\n",
      "Normal Saline\n",
      "mean    28.711246\n",
      "std     90.701748\n",
      "Name: Normal Saline, dtype: float64\n",
      "O2 Saturation\n",
      "mean    96.853895\n",
      "std      4.434503\n",
      "Name: O2 Saturation, dtype: float64\n",
      "OR/PACU Crystalloid\n",
      "mean    1867.075862\n",
      "std     2029.506886\n",
      "Name: OR/PACU Crystalloid, dtype: float64\n",
      "PCO2\n",
      "mean    42.215574\n",
      "std     10.778417\n",
      "Name: PCO2, dtype: float64\n",
      "PO intake\n",
      "mean    165.731986\n",
      "std     137.050160\n",
      "Name: PO intake, dtype: float64\n",
      "PO2\n",
      "mean    129.441199\n",
      "std      77.889951\n",
      "Name: PO2, dtype: float64\n",
      "PT\n",
      "mean    16.425192\n",
      "std      6.891606\n",
      "Name: PT, dtype: float64\n",
      "PTT\n",
      "mean    44.156472\n",
      "std     25.150656\n",
      "Name: PTT, dtype: float64\n",
      "Packed RBC\n",
      "mean    244.313406\n",
      "std     397.288377\n",
      "Name: Packed RBC, dtype: float64\n",
      "Pantoprazole\n",
      "mean    0.998039\n",
      "std     0.044196\n",
      "Name: Pantoprazole, dtype: float64\n",
      "Phosphate\n",
      "mean    3.611196\n",
      "std     1.423656\n",
      "Name: Phosphate, dtype: float64\n",
      "Piggyback\n",
      "mean    72.862050\n",
      "std     53.906076\n",
      "Name: Piggyback, dtype: float64\n",
      "Piperacillin\n",
      "mean    0.999782\n",
      "std     0.014774\n",
      "Name: Piperacillin, dtype: float64\n",
      "Platelet Count\n",
      "mean    217.312219\n",
      "std     142.249144\n",
      "Name: Platelet Count, dtype: float64\n",
      "Potassium\n",
      "mean    4.107533\n",
      "std     0.640878\n",
      "Name: Potassium, dtype: float64\n",
      "Pre-admission Intake\n",
      "mean    1917.993554\n",
      "std     2101.263520\n",
      "Name: Pre-admission Intake, dtype: float64\n",
      "Pre-admission Output\n",
      "mean    585.734579\n",
      "std     812.366016\n",
      "Name: Pre-admission Output, dtype: float64\n",
      "Propofol\n",
      "mean    155.113370\n",
      "std     150.823971\n",
      "Name: Propofol, dtype: float64\n",
      "RBC\n",
      "mean    3.370531\n",
      "std     0.581083\n",
      "Name: RBC, dtype: float64\n",
      "RDW\n",
      "mean    15.796506\n",
      "std      2.357414\n",
      "Name: RDW, dtype: float64\n",
      "RR\n",
      "mean    19.611439\n",
      "std      6.427721\n",
      "Name: RR, dtype: float64\n",
      "Residual\n",
      "mean    34.344104\n",
      "std     66.155824\n",
      "Name: Residual, dtype: float64\n",
      "SBP\n",
      "mean    121.324312\n",
      "std      23.961149\n",
      "Name: SBP, dtype: float64\n",
      "SG Urine\n",
      "mean    1.016901\n",
      "std     0.008150\n",
      "Name: SG Urine, dtype: float64\n",
      "Sodium\n",
      "mean    138.935644\n",
      "std       5.412374\n",
      "Name: Sodium, dtype: float64\n",
      "Solution\n",
      "mean    10.113233\n",
      "std     17.070926\n",
      "Name: Solution, dtype: float64\n",
      "Sterile Water\n",
      "mean    26.383229\n",
      "std     35.005937\n",
      "Name: Sterile Water, dtype: float64\n",
      "Stool\n",
      "mean    231.732733\n",
      "std     266.466449\n",
      "Name: Stool, dtype: float64\n",
      "TPN\n",
      "mean    68.713230\n",
      "std     35.136937\n",
      "Name: TPN, dtype: float64\n",
      "Temperature\n",
      "mean    37.004253\n",
      "std      0.844553\n",
      "Name: Temperature, dtype: float64\n",
      "Total CO2\n",
      "mean    26.053184\n",
      "std      5.889174\n",
      "Name: Total CO2, dtype: float64\n",
      "Ultrafiltrate\n",
      "mean    241.291126\n",
      "std     421.036856\n",
      "Name: Ultrafiltrate, dtype: float64\n",
      "Urine\n",
      "mean    126.601059\n",
      "std     137.560245\n",
      "Name: Urine, dtype: float64\n",
      "Vancomycin\n",
      "mean    1.000282\n",
      "std     0.067816\n",
      "Name: Vancomycin, dtype: float64\n",
      "Vasopressin\n",
      "mean    2.31758\n",
      "std     3.05247\n",
      "Name: Vasopressin, dtype: float64\n",
      "WBC\n",
      "mean    12.294918\n",
      "std      9.052268\n",
      "Name: WBC, dtype: float64\n",
      "Weight\n",
      "mean    84.374929\n",
      "std     25.456139\n",
      "Name: Weight, dtype: float64\n",
      "pH Blood\n",
      "mean    7.384243\n",
      "std     0.082493\n",
      "Name: pH Blood, dtype: float64\n",
      "pH Urine\n",
      "mean    5.762298\n",
      "std     0.951732\n",
      "Name: pH Urine, dtype: float64\n",
      "{'ALP': (154.62807595975605, 175.68338318171777), 'ALT': (245.08285008740046, 781.4634783618933), 'AST': (316.98250287918523, 1145.3431288077493), 'Age': (74.7962959466858, 54.740381481794905), 'Albumin': (2.7970520934259624, 0.6532167022201476), 'Albumin 25%': (64.73356945274655, 58.36021647016953), 'Albumin 5%': (311.8839976664918, 159.77739104632965), 'Amiodarone': (38.529795491457755, 26.307409229401685), 'Anion Gap': (13.700319706817956, 4.025733156551906), 'Antibiotics': (1.0, 1.0), 'BUN': (32.63386852356294, 25.762741074930915), 'Base Excess': (0.04056807313329922, 5.100586602669273), 'Basophils': (0.23510546706844596, 0.5487250780717937), 'Bicarbonate': (24.799388663554897, 5.25660838574317), 'Bilirubin (Direct)': (4.430013831258644, 5.869894434049498), 'Bilirubin (Indirect)': (2.0667107656689265, 2.608664818095121), 'Bilirubin (Total)': (4.06848979258311, 7.38523270773332), 'CRR': (0.046814515883224314, 0.20420234437297918), 'Calcium Free': (1.1319742701118176, 0.11312510321711114), 'Calcium Gluconate': (1.1931924850741666, 2.0552389481608553), 'Calcium Total': (8.336290985798104, 0.8428396929174271), 'Cefazolin': (1.0040760869565217, 0.06402938212145669), 'Chest Tube': (39.94371288523135, 77.12877458228704), 'Chloride': (104.92583816658266, 6.557634543160547), 'Colloid': (693.2400261689979, 1386.9590766307267), 'Creatinine Blood': (1.5443041601570944, 1.527146166109367), 'Creatinine Urine': (82.66354077863029, 61.05057596964794), 'D5W': (41.319437928252526, 79.48151917724967), 'DBP': (60.22055893530122, 14.646605377987242), 'Dextrose Other': (72.69370284153871, 67.17779898055755), 'Dobutamine': (23.437135526272876, 29.67681550152208), 'Dopamine': (26.417415308760855, 30.5369508561941), 'EBL': (503.28946597676463, 1101.237491646798), 'Emesis': (126.00187919463087, 161.99089585157535), 'Eoisinophils': (1.4791220942746448, 2.7826452267264914), 'Epinephrine': (0.1703024838366814, 0.5567188194252154), 'Famotidine': (1.0, 1.0), 'Fentanyl': (0.10334734776788393, 0.14179669066746983), 'FiO2': (0.49546249402896253, 0.15741773426923053), 'Fiber': (56.38560188752806, 38.51325692388802), 'Free Water': (164.5127655325321, 105.4881559244778), 'Fresh Frozen Plasma': (240.28154869313877, 288.32078224594153), 'Furosemide': (10.046007737577776, 13.290645134942087), 'GCS_eye': (3.2820050763594875, 1.061468857130494), 'GCS_motor': (5.271424328182657, 1.4103230111483216), 'GCS_verbal': (2.964442914775959, 1.9050695266863453), 'GT Flush': (51.024502837923094, 59.90224068428856), 'Gastric': (161.61713801050914, 187.5666456743802), 'Gastric Meds': (65.34854495443828, 93.29526461017704), 'Gender': (0.4367649002246597, 0.4959898854764211), 'Glucose (Blood)': (141.67232520561103, 55.695744719079386), 'Glucose (Serum)': (136.28548124213316, 60.25848921331334), 'Glucose (Whole Blood)': (132.329912592149, 44.97770827832524), 'HR': (87.01004778902707, 18.33365632576189), 'Half Normal Saline': (75.76175139941304, 89.85979673765948), 'Hct': (29.90547252036416, 4.814677440501103), 'Heparin': (1114.044957504194, 792.4585940805073), 'Hgb': (10.127966231317844, 1.7111970496283577), 'Hydralazine': (11.771232686498669, 4.97380251926607), 'Hydromorphone': (2.9171115818353766, 7.77626396159562), 'INR': (1.585325546719682, 1.1294986234534283), 'Insulin Humalog': (5.131419778963683, 5.680365353548814), 'Insulin NPH': (17.326917510853836, 14.400408957145325), 'Insulin Regular': (3.9435507394233817, 7.373560675119251), 'Insulin largine': (23.25353489429416, 16.090940845552684), 'Intubated': (0.819140464658074, 0.3849006724695242), 'Jackson-Pratt': (83.74960109737025, 120.17173517436434), 'KCl': (6.381031250911013, 8.841726585417524), 'KCl (Bolus)': (52.50344920589107, 17.7471011913005), 'LDH': (616.8442116764049, 1380.0092662397578), 'Lactate': (2.6615450107581613, 2.7258416943841115), 'Lactated Ringers': (139.50739678176876, 227.05989294707902), 'Levofloxacin': (0.9954805321415328, 0.04243196862153178), 'Lorazepam': (3.6040794444847277, 6.978262735115198), 'Lymphocytes': (11.765740047089041, 11.730555282149572), 'Lymphocytes (Absolute)': (989.3960396039604, 1160.2268796100586), 'MBP': (79.1817041212589, 17.064871735099487), 'MCH': (30.245121747124188, 2.261147330429214), 'MCHC': (33.699835054283284, 1.5914527504752178), 'MCV': (89.8504661136919, 6.2022213807417765), 'Magnesium': (2.070392349389516, 0.3870017729024219), 'Magnesium Sulfate (Bolus)': (49.42595511115775, 5.36245883334411), 'Magnesium Sulphate': (1.9210512893955067, 1.356351785601568), 'Mechanically ventilated': (1.0, 1.0), 'Metoprolol': (5.9936711200774475, 4.019041116677885), 'Midazolam': (3.489650827154437, 5.296791930143974), 'Milrinone': (1.6124673935338467, 1.2986414442525132), 'Monocytes': (4.871427034007749, 4.666159417379602), 'Morphine Sulfate': (5.612473235461167, 27.682521735248354), 'Neosynephrine': (4.91131656177251, 8.303942931323801), 'Neutrophils': (77.82038312526905, 16.4958181359713), 'Nitroglycerine': (5.0860144742695175, 7.363205328851184), 'Nitroprusside': (5.562782980421598, 8.60745588589139), 'Norepinephrine': (0.5459416199252402, 0.9343791488418172), 'Normal Saline': (28.711246288510196, 90.70174817580931), 'O2 Saturation': (96.85389464218684, 4.434502922400213), 'OR/PACU Crystalloid': (1867.0758617250206, 2029.506885583821), 'PCO2': (42.21557403380449, 10.778417488423155), 'PO intake': (165.7319857329148, 137.05015963939715), 'PO2': (129.4411986369915, 77.88995063568014), 'PT': (16.425192257152005, 6.891605641958025), 'PTT': (44.1564721388884, 25.150655761289954), 'Packed RBC': (244.3134062074202, 397.2883767122298), 'Pantoprazole': (0.9980388358917244, 0.04419631382240878), 'Phosphate': (3.61119620260008, 1.4236559288114496), 'Piggyback': (72.86204960763712, 53.9060758474529), 'Piperacillin': (0.9997816866267465, 0.014774048867050513), 'Platelet Count': (217.31221865164818, 142.24914442645618), 'Potassium': (4.1075327990477595, 0.64087806545563), 'Pre-admission Intake': (1917.9935536894027, 2101.263519905106), 'Pre-admission Output': (585.7345786963434, 812.3660156520959), 'Propofol': (155.1133696597117, 150.82397107904), 'RBC': (3.370531370808196, 0.581082604738683), 'RDW': (15.796505549525577, 2.357414348350964), 'RR': (19.6114388160697, 6.427720868560738), 'Residual': (34.34410373225863, 66.15582444548961), 'SBP': (121.3243122350447, 23.96114893359284), 'SG Urine': (1.016900823364458, 0.008150404248717635), 'Sodium': (138.9356436589571, 5.412373909672931), 'Solution': (10.113232995626756, 17.070925760968517), 'Sterile Water': (26.383229372075707, 35.00593652449287), 'Stool': (231.7327328146209, 266.46644936029264), 'TPN': (68.713230174453, 35.13693687220432), 'Temperature': (37.00425272708175, 0.8445528985370296), 'Total CO2': (26.053184260078382, 5.8891744163455675), 'Ultrafiltrate': (241.2911255551098, 421.03685620318714), 'Urine': (126.60105867523808, 137.56024532073556), 'Vancomycin': (1.0002819754996748, 0.06781608801024272), 'Vasopressin': (2.317579991583606, 3.0524700332457826), 'WBC': (12.294917678681191, 9.052268234249215), 'Weight': (84.37492874593204, 25.456138562387505), 'pH Blood': (7.384242950385978, 0.08249255568760135), 'pH Urine': (5.762297921890515, 0.95173208017145)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44858,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89716it [00:00, 383054.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27399984it [01:20, 338369.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "bleb (48, 19015, 262)\n",
      "(19015,)\n",
      "y is: [0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fore_max_len = 880\n",
    "# Read data.\n",
    "# data_path = '/home/mitarb/fracarolli/files/230613_STraTS_preprocessed/mimic_iii_preprocessed.pkl'\n",
    "data, oc, train_ind, valid_ind, test_ind = pickle.load(open(data_path, 'rb'))\n",
    "means_stds = data.groupby(\"variable\").agg({\"mean\":\"first\", \"std\":\"first\"})\n",
    "#print(means_stds)\n",
    "mean_std_dict = dict()\n",
    "print(means_stds.keys)\n",
    "for pos, row in means_stds.iterrows():\n",
    "    print(pos)\n",
    "    print(row)\n",
    "    mean_std_dict[pos] = (float(row[\"mean\"]), float(row[\"std\"]))\n",
    "print(mean_std_dict)\n",
    "#raise Exception\n",
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour >= 0) & (data.hour <= 48)]\n",
    "old_oc = oc\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Fix age.\n",
    "data.loc[(data.variable == 'Age') & (data.value > 200), 'value'] = 91.4\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['in_hospital_mortality']).astype('float32')\n",
    "print(y.shape)\n",
    "#raise Exception\n",
    "data['ts_ind'] = data['ts_ind'].astype(int) \n",
    "N = int(data.ts_ind.max() + 1)\n",
    "\n",
    "# Create demographic/static data\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]  # reduce data to non-demo/non-static\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((int(N), D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[int(row.ts_ind), static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds == 0)*1 + (stds != 0)*stds\n",
    "demo = (demo-means)/stds\n",
    "\n",
    "# Trim to max len.\n",
    "data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "\n",
    "# Get N, V, var_to_ind.\n",
    "#N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "# V = len(varis)\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index': 'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind': 'min'}).reset_index().rename(columns={\n",
    "                                                            'obs_ind': 'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    times_inp[ts_ind, l] = row.hour\n",
    "    values_inp[ts_ind, l] = row.value\n",
    "    varis_inp[ts_ind, l] = row.vind\n",
    "\n",
    "w=0\n",
    "\n",
    "fore_in = []\n",
    "\n",
    "pred_data = data.loc[(data.hour>=0)&(data.hour<=48)]\n",
    "pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value':'first'}).reset_index()\n",
    "pred_data['vind_value'] = pred_data[['vind', 'value']].values.tolist()\n",
    "pred_data = pred_data.groupby('ts_ind').agg({'vind_value':list}).reset_index()\n",
    "pred_data['vind_value'] = pred_data['vind_value'].apply(f)   \n",
    "\n",
    "obs_data = data.loc[(data.hour < 48) & (data.hour >= 0)]\n",
    "resultdict = dict()\n",
    "for ts_ind in obs_data.ts_ind:\n",
    "    resultdict[ts_ind] = [[]]\n",
    "obs_data = obs_data.loc[obs_data.ts_ind.isin(pred_data.ts_ind)]\n",
    "obs_data = obs_data.groupby('ts_ind').head(fore_max_len)\n",
    "obs_data = obs_data.groupby('ts_ind').agg({'vind': list, 'hour': list, 'value': list}).reset_index()\n",
    "\n",
    "for pred_window  in range(0, 48, 1):\n",
    "    print(pred_window)\n",
    "    #print(w+1 +pred_window)\n",
    "    #print(w+pred_window)\n",
    "    pred_data = data.loc[(data.hour >= w+pred_window) & (data.hour <= w+1 +pred_window)]\n",
    "    pred_data = pred_data.groupby(['ts_ind', 'vind']).agg({'value': 'first'}).reset_index()\n",
    "    pred_data['vind_value'+str(pred_window)] = pred_data[['vind', 'value']].values.tolist()\n",
    "    pred_data = pred_data.groupby('ts_ind').agg({'vind_value'+str(pred_window): list}).reset_index()\n",
    "    pred_data['vind_value'+str(pred_window)] = pred_data['vind_value'+str(pred_window)].apply(f)  # 721 entries with 2*129 vind_values\n",
    "    obs_data = obs_data.merge(pred_data, on='ts_ind')\n",
    "    #print(list(data['vind_value'+str(pred_window)]))\n",
    "    #print(len(list(data['vind_value'+str(pred_window)])))\n",
    "    #print(len(list(data['vind_value'+str(pred_window)])[0]))\n",
    "\n",
    "blub = (np.array(list([list(obs_data['vind_value'+str(pred_window)]) for pred_window in range(0, 48, 1)])))\n",
    "print(\"bleb\", blub.shape)\n",
    "op = np.swapaxes(blub, 0, 1)\n",
    "\n",
    "weird_oc = oc.loc[oc.ts_ind.isin(obs_data.ts_ind)]\n",
    "y = np.array(weird_oc.sort_values(by='ts_ind')['in_hospital_mortality']).astype('float32')\n",
    "print(y.shape)\n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "\n",
    "train_ind = [x for x in train_ind if x < op.shape[0]]\n",
    "valid_ind = [x for x in valid_ind if x < op.shape[0]]\n",
    "test_ind = [x for x in test_ind if x < op.shape[0]]\n",
    "\n",
    "train_input = op[train_ind]\n",
    "valid_input = op[valid_ind]\n",
    "test_input = op[test_ind]\n",
    "\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "del demo, times_inp, values_inp, varis_inp  # warum wird demo nicht gelöscht?\n",
    "\n",
    "if test_cond == 1:\n",
    "    tr_ind = [divmod(tr, 12)[0] for tr in train_ind]\n",
    "    va_ind = [divmod(tr, 12)[0] for tr in valid_ind]\n",
    "    te_ind = [divmod(tr, 12)[0] for tr in test_ind]\n",
    "    \n",
    "    train_op = y[tr_ind]  # is a problem for the test case...\n",
    "    valid_op = y[va_ind]\n",
    "    test_op = y[te_ind]\n",
    "else:\n",
    "    train_op = y[train_ind]  # is a problem for the test case...\n",
    "    valid_op = y[valid_ind]\n",
    "    test_op = y[test_ind]\n",
    "print('y is:', y)\n",
    "del y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c2f511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:42:20.709033Z",
     "iopub.status.busy": "2023-12-19T14:42:20.708722Z",
     "iopub.status.idle": "2023-12-19T14:45:37.617880Z",
     "shell.execute_reply": "2023-12-19T14:45:37.616614Z"
    }
   },
   "outputs": [],
   "source": [
    "#Michi: speichern wir mal fore_train_op, fore_valid_op, damit man nicht immer das Preprocessing laufen lassen muss\n",
    "with open(\"very_important.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump([fore_train_op, fore_valid_op], pickle_file, protocol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dea50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:45:37.622637Z",
     "iopub.status.busy": "2023-12-19T14:45:37.622299Z",
     "iopub.status.idle": "2023-12-19T14:50:41.174687Z",
     "shell.execute_reply": "2023-12-19T14:50:41.173486Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"very_important.pkl\", \"rb\") as pickle_file:\n",
    "    fore_train_op, fore_valid_op=pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd8241f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:50:41.179313Z",
     "iopub.status.busy": "2023-12-19T14:50:41.178967Z",
     "iopub.status.idle": "2023-12-19T14:50:41.208192Z",
     "shell.execute_reply": "2023-12-19T14:50:41.207507Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Michi: die ganzen Argparses könnte man noch anders implementieren, wollte es nur schnell zum laufen bringen.\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, required=False, default=1, help='status')\n",
    "parser.add_argument('--train_only', type=bool, required=False, default=False, help='perform training on full input dataset without validation and testing')\n",
    "parser.add_argument('--model_id', type=str, required=False, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=False, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=False, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=24, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=0, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')\n",
    "\n",
    "\n",
    "# DLinear\n",
    "parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "# Formers \n",
    "#Michi: bisher nur default=3 zum laufen gebracht\n",
    "parser.add_argument('--embed_type', type=int, default=3, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "parser.add_argument('--enc_in', type=int, default=262, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "parser.add_argument('--dec_in', type=int, default=131, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=131, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "import importlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b118361e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T06:00:27.622150Z",
     "iopub.status.busy": "2023-12-20T06:00:27.621806Z",
     "iopub.status.idle": "2023-12-21T21:06:12.939309Z",
     "shell.execute_reply": "2023-12-21T21:06:12.937726Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.000000:   3%|▎         | 103/3200 [00:07<03:31, 14.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_775408/1539023725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Linear'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"Autoregressive\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, enc_self_mask=input_mask, dec_self_mask=output_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"Linear\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, enc_self_mask=input_mask, dec_self_mask=output_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/strats_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/mitarb/staniek/strats_pytorch/LTSFLinear/models/InformerAutoregressiveSchedule.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask, trainn, tgt, backprop, mode, schedule, probability, deterministic)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;31m#print(linear_memory.size(), output.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/strats_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/strats_pytorch/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/strats_pytorch/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/strats_pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_ims_fr_backprop2_schedule_random.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False, schedule=True, deterministic=False, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954884fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T21:06:12.945699Z",
     "iopub.status.busy": "2023-12-21T21:06:12.945192Z",
     "iopub.status.idle": "2023-12-23T03:23:27.584965Z",
     "shell.execute_reply": "2023-12-23T03:23:27.582584Z"
    }
   },
   "outputs": [],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_informer_ims_fr_detach2_schedule_random.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])# ITF\n",
    "        \n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False,  schedule=True, deterministic=False, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Detach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca78c6b",
   "metadata": {},
   "source": [
    "# Scheduled Sampling DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3746c08c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T13:04:18.890893Z",
     "iopub.status.busy": "2023-12-23T13:04:18.890581Z",
     "iopub.status.idle": "2023-12-23T13:04:18.894529Z",
     "shell.execute_reply": "2023-12-23T13:04:18.893645Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Michi: die ganzen Argparses könnte man noch anders implementieren, wollte es nur schnell zum laufen bringen.\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, required=False, default=1, help='status')\n",
    "parser.add_argument('--train_only', type=bool, required=False, default=False, help='perform training on full input dataset without validation and testing')\n",
    "parser.add_argument('--model_id', type=str, required=False, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=False, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=False, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=24, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=0, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')\n",
    "\n",
    "\n",
    "# DLinear\n",
    "parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "# Formers \n",
    "#Michi: bisher nur default=3 zum laufen gebracht\n",
    "parser.add_argument('--embed_type', type=int, default=3, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "parser.add_argument('--enc_in', type=int, default=262, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "parser.add_argument('--dec_in', type=int, default=131, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=131, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "import importlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_ims_fr_backprop2_schedule.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False, schedule=True, deterministic=True, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0691d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_informer_ims_fr_detach2_schedule.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False,  schedule=True, deterministic=True, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Detach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5001af6",
   "metadata": {},
   "source": [
    "# Scheduled Sampling DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9912011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_ims_fr_backprop2_schedule_dtf.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])\n",
    "        prob = max([0.25, 0.25+(1.0-0.25)*(1-e/200)]) #DTF\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False, schedule=True, deterministic=True, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04188ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.InformerAutoregressiveSchedule as autoformer\n",
    "importlib.reload(autoformer)\n",
    "model = autoformer.Model(args).cuda()\n",
    "\n",
    "lr, batch_size, samples_per_epoch, patience = 0.0005, 32, int(102400/sample_divisor), 6\n",
    "d, N, he, dropout = 50, 2, 4, 0.2\n",
    "V=131\n",
    "print('number of parameters: ', V)\n",
    "\n",
    "\n",
    "#a = summary(model, [(32, 2), (32, 880), (32, 880), (32, 880)],  # shape of fore_train_ip\n",
    "#            dtypes=[torch.float, torch.float, torch.float, torch.long])\n",
    "#print(a)  # Model summary\n",
    "# raise Exception\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "# Pretrain fore_model.\n",
    "best_val_loss = np.inf\n",
    "N_fore = len(fore_train_op)\n",
    "#print(N_fore)\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_informer_ims_fr_detach2_schedule_dtf.pytorch'\n",
    "loss_func = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# torch.compile(model)\n",
    "for e in range(number_of_epochs):\n",
    "    e_indices = np.random.choice(range(N_fore), size=samples_per_epoch, replace=False)\n",
    "    e_loss = 0\n",
    "    pbar = tqdm(range(0, len(e_indices), batch_size))\n",
    "    model.train()\n",
    "    for start in pbar:\n",
    "        ind = e_indices[start:start+batch_size]\n",
    "\n",
    "        matrix = torch.tensor(fore_train_op[ind], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        \n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(str(type(model)))\n",
    "        #print(model)\n",
    "        prob=min([1.0, 1.0+(0.25-1.0)*(1-e/200)])\n",
    "        prob = max([0.25, 0.25+(1.0-0.25)*(1-e/200)]) #DTF\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, tgt=output_matrix, trainn=True, backprop=False,  schedule=True, deterministic=True, probability=prob)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        e_loss += loss.detach()\n",
    "        pbar.set_description('%f' % e_loss)\n",
    "    val_loss = 0\n",
    "    #raise Exception\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    pbar = tqdm(range(0, len(fore_valid_op), 32))  # len(fore_valid_op)           ####################   maybe also batch_size instead of 32\n",
    "    for start in pbar:\n",
    "        matrix = torch.tensor(fore_train_op[start:start+batch_size], dtype=torch.float32).cuda()\n",
    "        #torch.Size([32, 48, 258])\n",
    "        input_matrix = matrix[:, :24, :262]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        input_mark = torch.arange(0, input_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        input_mask = matrix[:, :24, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_matrix = matrix[:, 24:, :131]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        output_mark = torch.arange(0, output_matrix.size(1)).unsqueeze(0).repeat(input_matrix.size(0), 1).cuda()\n",
    "        #torch.Size([32, 24])\n",
    "        output_mask = matrix[:, 24:, 131:]\n",
    "        #torch.Size([32, 24, 129])\n",
    "        dec_inp = torch.zeros_like(output_matrix[:, -args.pred_len:, :]).float()\n",
    "        #print(dec_inp.size())\n",
    "        #dec_inp = torch.cat([output_matrix[:, :args.label_len, :], dec_inp], dim=1).float().cuda()\n",
    "        #raise Exception\n",
    "        #print(repr(model))\n",
    "        if 'Linear' not in str(type(model)) and \"Autoregressive\" in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark, trainn=False)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "        elif \"Linear\" not in str(type(model)):\n",
    "            output = model(input_matrix, input_mark, dec_inp, output_mark)#, enc_self_mask=input_mask, dec_self_mask=output_mask)\n",
    "\n",
    "        else:\n",
    "            output = model(input_matrix)[:, :, :131]\n",
    "        loss = output_mask[:, -args.pred_len:, :]*(\n",
    "        output-output_matrix[:, -args.pred_len:, :])**2\n",
    "        loss_list.extend(loss.sum(axis=-1).mean(axis=-1).detach().cpu().tolist())\n",
    "        loss = loss.sum(axis=-1).mean()\n",
    "        val_loss += loss.detach().cpu()\n",
    "        pbar.set_description('%f' % val_loss)\n",
    "    loss_p = e_loss*batch_size/samples_per_epoch\n",
    "    val_loss_p = val_loss*batch_size/len(fore_valid_op)\n",
    "    print('Epoch', e, 'loss', loss_p, 'val loss', val_loss_p, \"mean and std\", np.mean(loss_list), np.std(loss_list))\n",
    "    with open('loss_values_log', 'a') as f:\n",
    "        f.write(str(e)+' ' + str(loss_p.item()) + ' ' + str(val_loss_p.item())+ '\\n')\n",
    "    scheduler.step(val_loss_p.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), fore_savepath)\n",
    "        best_epoch = e\n",
    "    if (e-best_epoch) > patience:\n",
    "        break\n",
    "    \n",
    "print('Training has ended.')\n",
    "\n",
    "#Informer IMS, Sampling, Detach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ac620",
   "metadata": {},
   "source": [
    "# Scheduled Sampling RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d9056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
